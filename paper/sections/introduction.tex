% Example citation: ~\cite{sucerquia2017sisfall} <- this tilde ( $\Tilde{}$ ) adds small space right before adding the citation number

Falls represent a critical health concern for older adults, accounting for over 38 million medically treated injuries annually worldwide~\cite{who2021falls}. Wearable fall detection systems offer a promising solution for continuous, non-intrusive monitoring using commodity devices such as smartwatches. However, developing accurate fall detection models that operate within the computational and power constraints of wearable devices remains challenging.

\begin{figure}[htb!]
\centering
    \includegraphics[width=0.9\textwidth]{figures/similar_patterns.pdf}
    \caption{Illustration of the failure mode introduced by raw gyroscope signals from SmartFallMM dataset~\cite{smartfallmm2025}: The left column shows an activity of daily living, namely sitting down on a chair followed by standing up, while the right column shows a true back fall. The top row reports triaxial accelerometer signals ($m/s^2$), and the bottom row reports triaxial gyroscope angular velocities ($rad/s$).}
    \label{fig:similar_patterns}
\end{figure}

Modern smartwatches contain inertial measurement units (IMUs) comprising triaxial accelerometers and gyroscopes. While accelerometers measure linear acceleration and provide reliable impact detection, gyroscopes measure angular velocity and capture rotational motion patterns that often precede or accompany falls. Intuitively, combining both modalities should improve detection performance. However, preliminary analysis revealed an unexpected pattern: adding raw gyroscope data to accelerometer-only models degraded performance by 6.2\% in F1 score~\cite{s25175249}. This degradation occurs because angular velocity signals exhibit similar rotational patterns in both falls and certain daily activities, which confuses the model.
% 1.6--2.0\% {\color{blue} Need a reference here}
%Our analysis 
%The study also revealed that single-stream architectures, which process concatenated accelerometer and gyroscope channels through shared convolutional layers, allow noisy gyroscope signals to corrupt discriminative accelerometer features. The gyroscopes in consumer-grade micro-electro-mechanical systems (MEMS) exhibit substantial measurement noise and bias drift. When mixed with accelerometer signals in early network layers, this noise propagates through the network and degrades classification accuracy.

% A concrete example arises during activities such as sitting down quickly or lying down on a bed, as illustrated in Figure~\ref{fig:similar_patterns}. These actions involve pronounced trunk rotation, producing large gyroscope responses, while the corresponding linear acceleration remains moderate. When gyroscope channels are concatenated with accelerometer signals in a single processing stream, the network may incorrectly associate strong rotational patterns with falls, leading to false positives. Conversely, some real falls, such as back falls, exhibit clear impact signatures but relatively modest angular velocities. In these cases, noisy gyroscope measurements can obscure discriminative accelerometer features, increasing false negatives.

% This issue is exacerbated by the characteristics of consumer-grade micro-electro-mechanical systems (MEMS) gyroscopes. These sensors suffer from measurement noise and bias drift, and their angular velocity outputs lack an absolute reference. When accelerometer and gyroscope channels are jointly processed through shared early convolutional layers, as in single-stream architectures, gyroscope noise propagates into the learned representations. This cross-modal interference degrades the quality of accelerometer-derived impact features that are critical for reliable fall detection.

A concrete example arises during activities such as sitting down quickly or back falls, as illustrated in Figure~\ref{fig:similar_patterns}. These actions involve controlled trunk rotation, which produces large angular velocity responses in the gyroscope, while the corresponding linear acceleration remains moderate and lacks a distinct impact peak. In consumer-grade micro-electro-mechanical systems (MEMS) sensors, gyroscope measurements are further affected by noise and bias drift, and do not provide an absolute orientation reference. As a result, the resulting angular velocity during these daily activities can closely resemble that observed during back falls, despite fundamentally different physical outcomes. In such a scenario, when accelerometer and gyroscope channels are concatenated and processed through shared early convolutional layers in a single-stream architecture, the model may assign excessive importance to these rotational patterns. This leads to non-fall activities being misclassified as falls, increasing false positives. Conversely, for genuine falls characterized by a sharp acceleration peak but relatively low angular velocities, gyroscope noise can dilute the impact-related features, increasing false negatives.

These observations highlight a fundamental limitation of naively fusing raw IMU modalities. Such fusion can introduce ambiguity and noise that undermine classification accuracy, motivating the need for both signal-level transformation and architecture-level decoupling.

To overcome this limitation, we present a dual-stream transformer architecture that effectively leverages both accelerometer and gyroscope data through two key innovations:
\textbf{(1) Kalman Sensor Fusion:} Rather than using raw gyroscope angular velocities, we apply a Linear Kalman Filter~\cite{kalman1960new} to fuse accelerometer and gyroscope measurements, estimating body orientation angles (roll, pitch, yaw) in radians. This transforms noisy angular velocity signals, which lack an absolute reference and accumulate drift, into semantically meaningful body pose features. The resulting orientation representation captures \textit{what position the body is in} rather than \textit{how fast it is rotating}, providing more interpretable features for fall classification.
\textbf{(2) Dual-Stream Architecture:} We process accelerometer and Kalman-fused orientation streams through separate encoder pathways before fusion. Each stream has dedicated Conv1D projection layers, batch normalization, and dropout rates tuned to the signal characteristics of that modality. This separation prevents cross-modal interference while allowing the subsequent transformer encoder to learn joint temporal patterns across both streams.
Our architecture further incorporates Squeeze-and-Excitation (SE) channel attention~\cite{hu2018squeeze} to weight the importance of fused feature channels, and Temporal Attention Pooling (TAP) to focus classification on the most discriminative timesteps within each window, typically the impact phase of falls.
We evaluate our approach on three comprehensive fall detection datasets using Leave-One-Subject-Out cross-validation, achieving state-of-the-art performance for wearable IMU-based systems.
%the SmartFallMM dataset~\cite{ngu2022personalized}, a comprehensive multimodal fall detection benchmark comprising 30 young adult subjects performing 14 activities (9 activities of daily living and 5 fall types). Using rigorous 21-fold Leave-One-Subject-Out Cross-Validation (LOSO-CV),{\color{blue} Why do we need to use 21 here? Better to say K-fold and K is one}  our dual-stream Kalman transformer achieves 91.10\% F1 score, establishing a new state-of-the-art for IMU-based fall detection on this dataset.
The main contributions of this paper are:
\begin{enumerate}
    \item We demonstrate that raw gyroscope data hurts fall detection performance when processed in a single-stream architecture, but \textit{improves} performance when transformed through Kalman sensor fusion and processed in a dual-stream architecture.
    \item We present a dual-stream transformer architecture that processes accelerometer and orientation streams separately, achieving +1.30\% F1 improvement over single-stream Kalman baselines (89.80\% $\rightarrow$ 91.10\%).
    \item We provide comprehensive ablation studies quantifying the contribution of each architectural component: Kalman fusion enables +3.52\% F1 improvement in dual-stream context (87.58\% $\rightarrow$ 91.10\%), dual-stream processing contributes +1.30\% F1, and SE+TAP attention mechanisms contribute +1.28\% F1.
    %\item We characterize failure modes, finding that subjects exhibiting gentle, controlled falls with very low peak accelerations account for the majority of misclassifications, suggesting directions for future improvement.
\end{enumerate}

The remainder of this paper is organized as follows. Section~\ref{sec:related_work} reviews related work. Section~\ref{sec:materials} describes the proposed methodology, including a preprocessing pipeline and a dual-stream network architecture. Section~\ref{sec:implementation_det} describes implementation details, and Section~\ref{sec:results} presents experimental results including ablation studies. Section~\ref{sec:discussion} discusses implications and limitations. Finally, Section~\ref{sec:conclusions} concludes with future directions.


